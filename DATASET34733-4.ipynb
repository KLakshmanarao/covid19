{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "import random \n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilization of \n",
    "# Data set\n",
    "\n",
    "# defining the columns using normal distribution \n",
    "# np.random.randint(0, 2, 5) --> To produces 5 numbers. Each no is either 0 or 1 \n",
    "# column 1  Symptom-I\n",
    "cold = np.zeros((119711,), dtype=int)\n",
    "# column 2  Symptom2\n",
    "cough = np.zeros((119711,), dtype=int)\n",
    "# column 3 Symptom3\n",
    "feaver = np.zeros((119711,), dtype=int)\n",
    "# column 4 Symptom4\n",
    "breating = np.zeros((119711,), dtype=int)\n",
    "# Column 5 Symptom 5\n",
    "cronic = np.zeros((119711,), dtype=int)\n",
    "# Column 6 \n",
    "age = np.zeros((119711,), dtype=int) #\n",
    "#Column 7 The output either Covid-19 or NON-Covid\n",
    "#disease = np.random.randint(1, 10, 500)\n",
    "disease = np.zeros(119711, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Symptoms(GS) are 321. It is multiplied with 7. Hence, 321*7=2247\n",
    "b=0\n",
    "for i in range(0,2247):  #This is to fill General Symptoms  (GS-->1 in disease column)\n",
    "    b=b+1\n",
    "    if(b==1):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0  # age=0 indicates that age not considered it may be of any age\n",
    "        disease[i]=1\n",
    "    if(b==2):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==3):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==4):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==5):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==6):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==7):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=0\n",
    "        disease[i]=1\n",
    "    if(b==7):\n",
    "        b=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR1 is 116. It is multiplied with 16. Hence, 116*16=1856. It is from 2247+1856=4103\n",
    "b=0\n",
    "for i in range(2247,4103):  #This is to fill   (HR1-->2 in disease column) or Low Risk\n",
    "    b=b+1\n",
    "    if(b==1):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1        # age=1 indicates that age > 60\n",
    "        disease[i]=2\n",
    "    if(b==2):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==3):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==4):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==5):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==6):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==7):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==8):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==9):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==10):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==11):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==12):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==13):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==14):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==15):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=0\n",
    "        age[i]=1\n",
    "        disease[i]=2\n",
    "    if(b==15):\n",
    "        b=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR2 is 67. It is multiplied with 16. Hence, 67*16=1072. It is from 4103+1072=5175\n",
    "b=0\n",
    "for i in range(4103,5175):  #This is to fill   (HR2-->3 in disease column) or Medium Risk\n",
    "    b=b+1\n",
    "    if(b==1):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2           #2 indicates that the age is <60\n",
    "        disease[i]=3\n",
    "    if(b==2):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==3):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==4):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==5):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==6):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==7):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==8):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==9):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==10):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==11):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==12):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==13):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==14):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==15):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=2\n",
    "        disease[i]=3\n",
    "    if(b==15):\n",
    "        b=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR3 is 77. It is multiplied with 16. Hence, 77*16=1232. It is from 5175+1232=6407\n",
    "b=0\n",
    "for i in range(5175,6407):  #This is to fill   (HR3-->4 in disease column)\n",
    "    b=b+1\n",
    "    if(b==1):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==2):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==3):\n",
    "        cold[i]=0\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==4):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==5):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==6):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==7):\n",
    "        cold[i]=0\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==8):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==9):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==10):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==11):\n",
    "        cold[i]=1\n",
    "        cough[i]=0\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==12):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==13):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=0\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==14):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=0\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==15):\n",
    "        cold[i]=1\n",
    "        cough[i]=1\n",
    "        feaver[i]=1\n",
    "        breating[i]=1\n",
    "        cronic[i]=1\n",
    "        age[i]=1\n",
    "        disease[i]=4\n",
    "    if(b==15):\n",
    "        b=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.head()\n",
    "data = pd.DataFrame()\n",
    "data['cold']=cold\n",
    "data['cough']=cough\n",
    "data['feaver']=feaver\n",
    "data['breating']=breating\n",
    "data['cronic']=cronic\n",
    "data['age']=age\n",
    "data['disease']=disease\n",
    "#data\n",
    "#data.head()\n",
    "    \n",
    "#c=np.array(data.loc[3, ['cold', 'cough', 'feaver']])\n",
    "#c.any()\n",
    "#c.all()\n",
    "data.to_csv('ds-covid-new34733-119711.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold</th>\n",
       "      <th>cough</th>\n",
       "      <th>feaver</th>\n",
       "      <th>breating</th>\n",
       "      <th>cronic</th>\n",
       "      <th>age</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69364</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cold  cough  feaver  breating  cronic  age  disease\n",
       "8859      0      0       0         0       0    0        0\n",
       "16345     0      0       0         0       0    0        0\n",
       "22936     0      0       0         0       0    0        0\n",
       "49845     0      0       0         0       0    0        0\n",
       "69364     0      0       0         0       0    0        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ds-covid-new34733-119711.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of algorithms before balancing a dataset\n",
    "\n",
    "\n",
    "Add corresponding code in below cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113304\n",
       "1      2247\n",
       "2      1856\n",
       "4      1232\n",
       "3      1072\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.disease.value_counts() #disease is a field name and it is dependent or output variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cold        int64\n",
       "cough       int64\n",
       "feaver      int64\n",
       "breating    int64\n",
       "cronic      int64\n",
       "age         int64\n",
       "disease     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from tensorflow_addons import losses\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('disease',axis='columns')\n",
    "y = df['disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79274\n",
       "1     1572\n",
       "2     1316\n",
       "4      885\n",
       "3      750\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34030\n",
       "1      675\n",
       "2      540\n",
       "4      347\n",
       "3      322\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Linear Regression: Accuracy of Training data: 0.9999761327971168\n",
      "\n",
      " The Linear Regression: Accuracy of Testine data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "train_acc=lr.predict(X_train)\n",
    "train_score=metrics.accuracy_score(y_train, train_acc)\n",
    "y_pred_lr=lr.predict(X_test)\n",
    "test_scores=metrics.accuracy_score(y_test, y_pred_lr)\n",
    "print(\"\\n The Linear Regression: Accuracy of Training data:\",train_score)\n",
    "print(\"\\n The Linear Regression: Accuracy of Testine data:\",test_scores)\n",
    "lr_cm1=confusion_matrix(y_test, y_pred_lr)\n",
    "lr_cm1\n",
    "lr_cr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Classification Report:\\n\",lr_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 1.0\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive=GaussianNB()\n",
    "naive.fit(X_train, y_train)\n",
    "train_naive=naive.predict(X_train)\n",
    "naive_y_pred=naive.predict(X_test)\n",
    "train_naive_score=metrics.accuracy_score(y_train, train_naive)\n",
    "scores=metrics.accuracy_score(y_test, naive_y_pred)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",train_naive_score)\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",scores)\n",
    "naive_cm1=confusion_matrix(y_test, naive_y_pred)\n",
    "naive_cm1\n",
    "naive_cr = classification_report(y_test, naive_y_pred)\n",
    "print(\"Classification Report:\\n\",naive_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9999761327971168\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier(loss='modified_huber',shuffle=True,random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd=sgd.predict(X_test)\n",
    "scores=metrics.accuracy_score(y_test, y_pred_sgd)\n",
    "SGDTrain=sgd.predict(X_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_train,SGDTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",scores)\n",
    "sgd_cm1=confusion_matrix(y_test, y_pred_sgd)\n",
    "sgd_cm1\n",
    "sgd_cr = classification_report(y_test, y_pred_sgd)\n",
    "print(\"Classification Report:\\n\",sgd_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KNN: Accuracy of Training data: 0.9999880663985584\n",
      "\n",
      " KNN: Accuracy of Testing data: [1.0]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Code to find best K Value\n",
    "\n",
    "#Importing KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# try K=1 through K=25 and record testing accuracy\n",
    "\n",
    "#k_range = range(1, 26)\n",
    "\n",
    "# We can create Python dictionary using [] or dict()\n",
    "scores = []\n",
    "k=5\n",
    "# We use a loop through the range 1 to 26\n",
    "# We append the scores in the dictionary\n",
    "\n",
    "#for k in k_range:\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "knntrain=knn.predict(X_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "scores.append(metrics.accuracy_score(y_test, y_pred_knn))\n",
    "print(\"\\n KNN: Accuracy of Training data:\",accuracy_score(y_train,knntrain))\n",
    "print(\"\\n KNN: Accuracy of Testing data:\",scores)\n",
    "\n",
    "knn_cr = classification_report(y_test, y_pred_knn)\n",
    "print(\"Classification Report:\\n\",knn_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# cold\tcough\tfeaver\tbreating\tcronic\tage\n",
    "print(knn.predict([[1,1,0,0,0,0]]))# Prediction of a person with some diseases.\n",
    "#The output shows it is \"1\" Means GS,2 means HR1, 3 means HR2, and 4 means HR3.\n",
    "print(knn.predict([[1,1,0,1,0,0]]))\n",
    "print(knn.predict([[1,1,0,0,0,1]]))\n",
    "print(knn.predict([[1,1,0,1,1,0]]))\n",
    "print(knn.predict([[1,1,0,1,1,1]]))\n",
    "print(knn.predict([[1,1,0,0,1,1]]))\n",
    "print(knn.predict([[0,0,1,0,1,0]]))\n",
    "print(knn.predict([[0,0,0,0,0,0]]))\n",
    "print(knn.predict([[1,1,1,1,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34030,     0,     0,     0,     0],\n",
       "       [    0,   675,     0,     0,     0],\n",
       "       [    0,     0,   540,     0,     0],\n",
       "       [    0,     0,     0,   322,     0],\n",
       "       [    0,     0,     0,     0,   347]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "knncm1=confusion_matrix(y_test, y_pred_knn)\n",
    "knncm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "# gini model\n",
    "# -------------------------------------\n",
    "# Model 1) DT with gini index criteria\n",
    "clf_gini = dtc(criterion = \"gini\", random_state = 100, max_depth=3,\n",
    "               min_samples_leaf=5).fit(X_train, y_train)\n",
    "print(clf_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Testing Accuracy is  100.0\n",
      "Gini Training Accuracy is  99.99880663985584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "pred_gini = clf_gini.predict(X_test)\n",
    "DTTrain=clf_gini.predict(X_train)\n",
    "print(\"Gini Testing Accuracy is \", accuracy_score(y_test,pred_gini)*100)\n",
    "print(\"Gini Training Accuracy is \", accuracy_score(y_train,DTTrain)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34030,     0,     0,     0,     0],\n",
       "       [    0,   675,     0,     0,     0],\n",
       "       [    0,     0,   540,     0,     0],\n",
       "       [    0,     0,     0,   322,     0],\n",
       "       [    0,     0,     0,     0,   347]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm1=confusion_matrix(y_test, pred_gini)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DecisionTree: Accuracy of Testing data: 1.0\n",
      "\n",
      " DecisionTree: Accuracy of Training data: 0.9999880663985584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=10,random_state=101,max_features=None,min_samples_leaf=15)\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred_dtree=dtree.predict(X_test)\n",
    "dtreetrain=dtree.predict(X_train)\n",
    "scores=metrics.accuracy_score(y_test, y_pred_dtree)\n",
    "print(\"\\n DecisionTree: Accuracy of Testing data:\",scores)\n",
    "print(\"\\n DecisionTree: Accuracy of Training data:\",accuracy_score(y_train, dtreetrain))\n",
    "dtree_cm1=confusion_matrix(y_test, y_pred_dtree)\n",
    "dtree_cm1\n",
    "\n",
    "dtree_cr = classification_report(y_test, y_pred_dtree)\n",
    "print(\"Classification Report:\\n\",dtree_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForestClassifier: Accuracy of Testing data: 1.0\n",
      "\n",
      " RandomForestClassifier: Accuracy of Training data: 0.9999880663985584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfm=RandomForestClassifier(n_estimators=70,oob_score=True,n_jobs=-1,random_state=101,max_features=None,min_samples_leaf=30)\n",
    "rfm.fit(X_train, y_train)\n",
    "y_pred_rfm=rfm.predict(X_test)\n",
    "rfmtrain=rfm.predict(X_train)\n",
    "rfmscores=metrics.accuracy_score(y_test, y_pred_rfm)\n",
    "print(\"\\n RandomForestClassifier: Accuracy of Testing data:\",rfmscores)\n",
    "print(\"\\n RandomForestClassifier: Accuracy of Training data:\",accuracy_score(y_train, rfmtrain))\n",
    "\n",
    "rfm_cm1=confusion_matrix(y_test, y_pred_rfm)\n",
    "rfm_cm1\n",
    "\n",
    "\n",
    "rfm_cr = classification_report(y_test, y_pred_rfm)\n",
    "print(\"Classification Report:\\n\",rfm_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DecisionTree: Accuracy of Testing data: 1.0\n",
      "\n",
      " DecisionTree: Accuracy of Training data: 0.9999880663985584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34030\n",
      "           1       1.00      1.00      1.00       675\n",
      "           2       1.00      1.00      1.00       540\n",
      "           3       1.00      1.00      1.00       322\n",
      "           4       1.00      1.00      1.00       347\n",
      "\n",
      "    accuracy                           1.00     35914\n",
      "   macro avg       1.00      1.00      1.00     35914\n",
      "weighted avg       1.00      1.00      1.00     35914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM=SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred_SVM=SVM.predict(X_test)\n",
    "SVMtrain=SVM.predict(X_train)\n",
    "SVMscores=metrics.accuracy_score(y_test, y_pred_SVM)\n",
    "print(\"\\n DecisionTree: Accuracy of Testing data:\",SVMscores)\n",
    "print(\"\\n DecisionTree: Accuracy of Training data:\",accuracy_score(y_train, SVMtrain))\n",
    "\n",
    "SVM_cm1=confusion_matrix(y_test, y_pred_SVM)\n",
    "SVM_cm1\n",
    "\n",
    "svm_cr = classification_report(y_test, y_pred_SVM)\n",
    "print(\"Classification Report:\\n\",svm_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Methods for getting balanced dataset\n",
    "\n",
    "**for getting balanced data set.**\n",
    "\n",
    "1. SMOTE -- other forms of SMOTE--such as SMOTE(\"minority\") and SMOTE(sampling_strategy=strategy)\n",
    "2. ADASYN\n",
    "3. SMOTETomek\n",
    "4. SMOTEENN\n",
    "5. RandomUnderSampler\n",
    "\n",
    "To install imbalanced-learn library use **pip install imbalanced-learn** command\n",
    "\n",
    "The **stratify** option in train_test_split method gives 1.0 Accuracy. Which is uses as follows:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sm_train, X_sm_test, y_sm_train, y_sm_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)\n",
    "\n",
    "Where as **sometimes** without **stratify** option gives less accuracy for some balanced dataset methods. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sm_train, X_sm_test, y_sm_train, y_sm_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15)\n",
    "\n",
    "**The below code executes The RandomUndersampling followed by SMOTE to obtain balanced data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2247\n",
       "2    1856\n",
       "4    1232\n",
       "3    1072\n",
       "0    1072\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#under = RandomUnderSampler()\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_r, y_r=under.fit_sample(X,y)\n",
    "y_r.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    2247\n",
       "3    2247\n",
       "2    2247\n",
       "1    2247\n",
       "0    2247\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomUnderSampler followed by either SMOTE or ADASYN\n",
    "#Python code for SMOTE algorithm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE()\n",
    "X_rsm,y_rsm=smote.fit_resample(X_r,y_r)\n",
    "y_rsm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    651\n",
       "2    588\n",
       "4    373\n",
       "0    330\n",
       "3    302\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_rsm_train, X_rsm_test, y_rsm_train, y_rsm_test = train_test_split(X_r, y_r, test_size=0.3, random_state=15)\n",
    "y_rsm_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1596\n",
       "2    1268\n",
       "4     859\n",
       "3     770\n",
       "0     742\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rsm_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_rsm_train, y_rsm_train)\n",
    "lr_y_pred=lr.predict(X_rsm_test)\n",
    "lrscores=metrics.accuracy_score(y_rsm_test, lr_y_pred)\n",
    "lrTrain=lr.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,lrTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",lrscores)\n",
    "lr_cm1=confusion_matrix(y_rsm_test, lr_y_pred)\n",
    "lr_cm1\n",
    "\n",
    "lr_cr = classification_report(y_rsm_test, lr_y_pred)\n",
    "print(\"Classification Report:\\n\",lr_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 1.0\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.native_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(X_rsm_train, y_rsm_train)\n",
    "nb_y_pred=nb.predict(X_rsm_test)\n",
    "nbscores=metrics.accuracy_score(y_rsm_test, nb_y_pred)\n",
    "nbTrain=nb.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,nbTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",nbscores)\n",
    "Gaussian_cm1=confusion_matrix(y_rsm_test, nb_y_pred)\n",
    "Gaussian_cm1\n",
    "\n",
    "nb_cr = classification_report(y_rsm_test, nb_y_pred)\n",
    "print(\"Classification Report:\\n\",nb_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 1.0\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier(loss='modified_huber',shuffle=True,random_state=101)\n",
    "sgd.fit(X_rsm_train, y_rsm_train)\n",
    "y_pred_sgd=sgd.predict(X_rsm_test)\n",
    "sgdscores=metrics.accuracy_score(y_rsm_test, y_pred_sgd)\n",
    "sgdTrain=sgd.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,sgdTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",sgdscores)\n",
    "sgd_cm1=confusion_matrix(y_rsm_test, y_pred_sgd)\n",
    "sgd_cm1\n",
    "\n",
    "sgd_cr = classification_report(y_rsm_test, y_pred_sgd)\n",
    "print(\"Classification Report:\\n\",sgd_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_rsm = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_rsm.fit(X_rsm_train, y_rsm_train)\n",
    "y_rsm_pred = knn_rsm.predict(X_rsm_test)\n",
    "knnscores=metrics.accuracy_score(y_rsm_test, y_rsm_pred)\n",
    "knnTrain=knn_rsm.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,knnTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",knnscores)\n",
    "\n",
    "knn_cr = classification_report(y_rsm_test, y_rsm_pred)\n",
    "print(\"Classification Report:\\n\",knn_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[2]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# cold\tcough\tfeaver\tbreating\tcronic\tage\n",
    "print(knn.predict([[1,1,0,0,0,0]]))# Prediction of a person with some diseases.\n",
    "#The output shows it is \"1\" Means GS,2 means HR1, 3 means HR2, and 4 means HR3.\n",
    "print(knn_rsm.predict([[1,1,0,1,0,0]]))\n",
    "print(knn_rsm.predict([[1,1,0,0,0,1]]))\n",
    "print(knn_rsm.predict([[1,1,0,1,1,0]]))\n",
    "print(knn_rsm.predict([[1,1,0,1,1,1]]))\n",
    "print(knn_rsm.predict([[1,1,0,0,1,1]]))\n",
    "print(knn_rsm.predict([[0,0,1,0,1,0]]))\n",
    "print(knn_rsm.predict([[0,0,0,0,0,0]]))\n",
    "print(knn_rsm.predict([[1,1,1,1,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[330,   0,   0,   0,   0],\n",
       "       [  0, 651,   0,   0,   0],\n",
       "       [  0,   0, 588,   0,   0],\n",
       "       [  0,   0,   0, 302,   0],\n",
       "       [  0,   0,   0,   0, 373]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_rsm_cm1=confusion_matrix(y_rsm_test, y_rsm_pred)\n",
    "knn_rsm_cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "# gini model\n",
    "# -------------------------------------\n",
    "# Model 1) DT with gini index criteria\n",
    "rsm_clf_gini = dtc(criterion = \"gini\", random_state = 100, max_depth=3,\n",
    "               min_samples_leaf=5).fit(X_rsm_train, y_rsm_train)\n",
    "print(rsm_clf_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Gini: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The Gini: Accuracy of Testing data: 100.0\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "rsm_pred_gini = rsm_clf_gini.predict(X_rsm_test)\n",
    "#smote_pred_gini.value_counts()\n",
    "#print(\"Gini Accuracy is \", accuracy_score(y_rsm_test,rsm_pred_gini)*100)\n",
    "giniTrain=rsm_clf_gini.predict(X_rsm_train)\n",
    "print(\"\\n The Gini: Accuracy of Training data:\",accuracy_score(y_rsm_train,giniTrain))\n",
    "print(\"\\n The Gini: Accuracy of Testing data:\",accuracy_score(y_rsm_test,rsm_pred_gini)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[330,   0,   0,   0,   0],\n",
       "       [  0, 651,   0,   0,   0],\n",
       "       [  0,   0, 588,   0,   0],\n",
       "       [  0,   0,   0, 302,   0],\n",
       "       [  0,   0,   0,   0, 373]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "gini_rsm_cm1=confusion_matrix(y_rsm_test, rsm_pred_gini)\n",
    "gini_rsm_cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=10,random_state=101,max_features=None,min_samples_leaf=15)\n",
    "dtree.fit(X_rsm_train, y_rsm_train)\n",
    "y_pred_dtree=dtree.predict(X_rsm_test)\n",
    "dtreescores=metrics.accuracy_score(y_rsm_test, y_pred_dtree)\n",
    "dtreeTrain=dtree.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,dtreeTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",dtreescores)\n",
    "dtree_cm1=confusion_matrix(y_rsm_test, y_pred_dtree)\n",
    "dtree_cm1\n",
    "\n",
    "dtree_cr = classification_report(y_rsm_test, y_pred_dtree)\n",
    "print(\"Classification Report:\\n\",dtree_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfm=RandomForestClassifier(n_estimators=70,oob_score=True,n_jobs=-1,random_state=101,max_features=None,min_samples_leaf=30)\n",
    "rfm.fit(X_rsm_train, y_rsm_train)\n",
    "y_pred_rfm=rfm.predict(X_rsm_test)\n",
    "rfmscores=metrics.accuracy_score(y_rsm_test, y_pred_rfm)\n",
    "rfmTrain=rfm.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,rfmTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",rfmscores)\n",
    "rfm_cm1=confusion_matrix(y_rsm_test, y_pred_rfm)\n",
    "rfm_cm1\n",
    "\n",
    "rfm_cr = classification_report(y_rsm_test, y_pred_rfm)\n",
    "print(\"Classification Report:\\n\",rfm_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The naive_bayes: Accuracy of Training data: 0.9998089780324737\n",
      "\n",
      " The naive_bayes: Accuracy of Testing data: 1.0\n",
      "[[330   0   0   0   0]\n",
      " [  0 651   0   0   0]\n",
      " [  0   0 588   0   0]\n",
      " [  0   0   0 302   0]\n",
      " [  0   0   0   0 373]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       330\n",
      "           1       1.00      1.00      1.00       651\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       302\n",
      "           4       1.00      1.00      1.00       373\n",
      "\n",
      "    accuracy                           1.00      2244\n",
      "   macro avg       1.00      1.00      1.00      2244\n",
      "weighted avg       1.00      1.00      1.00      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM=SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
    "SVM.fit(X_rsm_train, y_rsm_train)\n",
    "y_pred_SVM=SVM.predict(X_rsm_test)\n",
    "svmscores=metrics.accuracy_score(y_rsm_test, y_pred_SVM)\n",
    "svmTrain=SVM.predict(X_rsm_train)\n",
    "print(\"\\n The naive_bayes: Accuracy of Training data:\",accuracy_score(y_rsm_train,svmTrain))\n",
    "print(\"\\n The naive_bayes: Accuracy of Testing data:\",svmscores)\n",
    "\n",
    "\n",
    "SVM_cm1=confusion_matrix(y_rsm_test, y_pred_SVM)\n",
    "print(SVM_cm1)\n",
    "\n",
    "SVM_cr = classification_report(y_rsm_test, y_pred_SVM)\n",
    "print(\"Classification Report:\\n\",SVM_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://analyticsindiamag.com/7-types-classification-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert Decimal number\n",
    "# to Binary number\n",
    "# def decimal_To_Binary(n):\n",
    "#     return bin(n).replace(\"0b\",\"\")\n",
    "# Driver code\n",
    "# if __name__ == '__main__':\n",
    "#     print(decimal_To_Binary(7))\n",
    "#     print(decimal_To_Binary(9))\n",
    "#     print(decimal_To_Binary(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimal_To_Binary(n):\n",
    "#     b=bin(n).replace(\"0b\",\"\")\n",
    "#     if n==0:\n",
    "#         return int(b[0]),0,0\n",
    "#     elif n==1:\n",
    "#         return 0,0,int(b[0])\n",
    "#     elif n==2:\n",
    "#         return 0,int(b[0]),int(b[1])\n",
    "#     elif n==3:\n",
    "#         return 0,int(b[0]),int(b[1])\n",
    "#     else:\n",
    "#         return int(b[0]),int(b[1]),int(b[2])\n",
    "    \n",
    "    \n",
    "# x,y,z=decimal_To_Binary(8)\n",
    "# print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def dectoOct(decimal):\n",
    "#    if(decimal > 0):\n",
    "#         dectoOct((int)(decimal/8))\n",
    "#         print(decimal%8, end='')\n",
    "        \n",
    "# decimal = int(input(\"Enter a decimal number \\n\"))\n",
    "# print(\"Octal: \", end='')\n",
    "# dectoOct(decimal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
